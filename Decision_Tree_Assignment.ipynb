{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7fe645-5e10-48b2-a98c-841ed1ecb56e",
   "metadata": {},
   "source": [
    "***Decision Tree | Assignment***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8475b55-cf57-491c-b65f-15d4fcaede90",
   "metadata": {},
   "source": [
    "# Question 1:  What is a Decision Tree, and how does it work in the context of classification? \n",
    "Answer:  \n",
    "- def :  \n",
    "A Decision Tree is a machine learning algorithm that is used for classification and regression tasks. In classification, it is used to predict the class (category) of a given input based on its features.\n",
    "\n",
    "- It works like a flowchart:\n",
    "\n",
    "Each internal node represents a condition on a feature (example: \"Is age > 18?\").\n",
    "\n",
    "Each branch represents the outcome of that condition (Yes/No).\n",
    "\n",
    "Each leaf node gives the final decision or class label.\n",
    "\n",
    "- Working in classification:\n",
    "\n",
    "The dataset is divided into smaller subsets based on the most important feature using measures like Gini Index or Information Gain.\n",
    "\n",
    "This splitting continues until all the data is perfectly classified or some stopping condition is reached.\n",
    "\n",
    "To classify a new example, the tree is followed from the root node to a leaf node by answering the conditions step by step.\n",
    "\n",
    "The class label of the reached leaf node is given as the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777746ec-2375-4082-9208-041c1f9154ce",
   "metadata": {},
   "source": [
    "# Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree? \n",
    "Answer:\n",
    "In a Decision Tree, we need to decide where to split the data. To do this, we measure how ‚Äúimpure‚Äù or ‚Äúmixed‚Äù the classes are in a node. Two common impurity measures are Gini Impurity and Entropy.\n",
    "\n",
    "- Gini Impurity\n",
    "\n",
    "Formula: \n",
    "Gini=1‚àí‚àëpi2‚Äã  \n",
    "here\n",
    "pi= probability of class i in the node.\n",
    "\n",
    "Gini tells us how often a randomly chosen element would be misclassified if we label it randomly according to the class distribution.\n",
    "\n",
    "Range: 0 (pure, only one class) to 0.5 (for 2 classes, completely mixed).\n",
    "\n",
    "Decision Trees (like CART) often use Gini because it is faster to calculate.\n",
    "\n",
    "- Entropy (Information Gain)\n",
    "\n",
    "Formula: \n",
    "Entropy=‚àí‚àëpi‚Äãlog2‚Äã(pi)\n",
    "Measures the uncertainty in the node.\n",
    "\n",
    "Range: 0 (pure) to 1 (for 2 classes equally mixed).\n",
    "\n",
    "When splitting, Decision Trees calculate Information Gain, which is the reduction in entropy after the split.\n",
    "\n",
    "- Impact on splits:\n",
    "\n",
    "Both Gini and Entropy try to create ‚Äúpure‚Äù child nodes (nodes with mostly one class).\n",
    "\n",
    "Gini tends to make splits that isolate the most frequent class quickly.\n",
    "\n",
    "Entropy is more sensitive to class distribution and can give slightly different splits.\n",
    "\n",
    "In practice, both often give similar results, but Gini is computationally simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fab406-17ac-4b43-96ce-5bab4e4159a1",
   "metadata": {},
   "source": [
    "# Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each. \n",
    "Answer: \n",
    "| **Aspect**       | **Pre-Pruning (Early Stopping)**                      | **Post-Pruning**                                    |\n",
    "| ---------------- | ----------------------------------------------------- | --------------------------------------------------- |\n",
    "| **When applied** | During tree building (stops splitting early)          | After the tree is fully grown                       |\n",
    "| **How it works** | Uses conditions like max depth, min samples, min gain | Removes branches that do not improve accuracy       |\n",
    "| **Goal**         | Prevent the tree from becoming too complex            | Simplify a fully grown tree without losing accuracy |\n",
    "| **Advantage**    | Saves time & computation, avoids very large trees     | Usually gives better accuracy and generalization    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a780fed-959e-4912-b10b-6f563c64bdd0",
   "metadata": {},
   "source": [
    "# Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split? \n",
    "Answer:\n",
    "Information Gain (IG):\n",
    "\n",
    "Information Gain measures the reduction in uncertainty (entropy) after splitting the data on an attribute.\n",
    "\n",
    "Formula:\n",
    "\n",
    "IG(S,A)=Entropy(S)‚àí‚àë‚à£S‚à£‚à£Sv‚Äã‚à£‚Äã√óEntropy(Sv‚Äã)\n",
    "\n",
    "where\n",
    "S is the dataset, and ùëÜùë£are the subset after sliting an attribute A\n",
    "\n",
    "- Meaning:\n",
    "\n",
    "High IG means the split gives more ‚Äúpure‚Äù subsets (less mixed classes).\n",
    "\n",
    "Low IG means the split does not help much in separating classes.\n",
    "\n",
    "- Importance in Decision Trees:\n",
    "\n",
    "Decision Trees use IG to choose the best attribute for splitting at each node.\n",
    "\n",
    "The attribute with the highest Information Gain is selected because it reduces uncertainty the most.\n",
    "\n",
    "This helps the tree make more accurate decisions and avoid useless splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f7d8e-fcdc-4d11-8a85-c71b9fead1fb",
   "metadata": {},
   "source": [
    "# Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations? \n",
    "Answer:\n",
    "1. Real-world applications of Decision Trees:\n",
    "\n",
    "Application\tExample\n",
    "Medical Diagnosis e.g:\tPredicting if a patient has a disease\n",
    "Credit Risk / Loan Approval e,g :\tApproving or rejecting loan applications\n",
    "Customer Churn Prediction\te,g:Predicting if a customer will leave a service\n",
    "Spam Email Detection\te,g:Classifying emails as spam or not spam\n",
    "Marketing & Sales\tDeciding which customers to target for a campaign\n",
    "\n",
    "2. Main Advantages:\n",
    "\n",
    "Easy to understand and interpret (like a flowchart)\n",
    "\n",
    "Can handle both numerical and categorical data\n",
    "\n",
    "No need for much data preprocessing\n",
    "\n",
    "Can reveal important features automatically\n",
    "\n",
    "3. Main Limitations:\n",
    "\n",
    "Can overfit if the tree is too deep\n",
    "\n",
    "Sensitive to small changes in data\n",
    "\n",
    "Not always the most accurate compared to ensemble methods (like Random Forest or XGBoost)\n",
    "\n",
    "Can be biased if some classes dominate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2125ca40-1ec7-413f-b8b5-759a83ad3a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 1.0\n",
      "\n",
      "Feature Importances:\n",
      "sepal length (cm): 0.0000\n",
      "sepal width (cm): 0.0191\n",
      "petal length (cm): 0.8933\n",
      "petal width (cm): 0.0876\n"
     ]
    }
   ],
   "source": [
    "#Question 6:   Write a Python program to: ‚óè Load the Iris Dataset ‚óè Train a Decision Tree Classifier using the Gini criterion ‚óè Print the model‚Äôs accuracy and feature importances \n",
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data   # Features\n",
    "y = iris.target # Labels\n",
    "\n",
    "# 2. Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train Decision Tree Classifier with Gini criterion\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 5. Model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# 6. Feature importances\n",
    "print(\"\\nFeature Importances:\")\n",
    "for name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c0b05e-0fad-49b6-aa1b-31ebd4ad5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree with max_depth=3: 1.0\n",
      "Accuracy of fully-grown Decision Tree: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Question 7:Write a Python program to: ‚óè Load the Iris Dataset ‚óè Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree. \n",
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2. Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train a Decision Tree with max_depth=3\n",
    "tree_limited = DecisionTreeClassifier(criterion=\"gini\", max_depth=3, random_state=42)\n",
    "tree_limited.fit(X_train, y_train)\n",
    "y_pred_limited = tree_limited.predict(X_test)\n",
    "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
    "\n",
    "# 4. Train a fully-grown Decision Tree (no max_depth)\n",
    "tree_full = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "tree_full.fit(X_train, y_train)\n",
    "y_pred_full = tree_full.predict(X_test)\n",
    "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
    "\n",
    "# 5. Print accuracies\n",
    "print(\"Accuracy of Decision Tree with max_depth=3:\", accuracy_limited)\n",
    "print(\"Accuracy of fully-grown Decision Tree:\", accuracy_full)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5042e04a-bdef-4347-9666-790ffe8aa3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5280096503174904\n",
      "\n",
      "Feature Importances:\n",
      "MedInc: 0.5235\n",
      "HouseAge: 0.0521\n",
      "AveRooms: 0.0494\n",
      "AveBedrms: 0.0250\n",
      "Population: 0.0322\n",
      "AveOccup: 0.1390\n",
      "Latitude: 0.0900\n",
      "Longitude: 0.0888\n"
     ]
    }
   ],
   "source": [
    "# Question 8: Write a Python program to: ‚óè Load the Boston Housing Dataset ‚óè Train a Decision Tree Regressor ‚óè Print the Mean Squared Error (MSE) and feature importances \n",
    "\n",
    "# Import required libraries\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Load California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# 2. Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Train Decision Tree Regressor\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predictions\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# 5. Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# 6. Feature importances\n",
    "print(\"\\nFeature Importances:\")\n",
    "for name, importance in zip(housing.feature_names, regressor.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7af5277-9773-44ad-92b0-37cf8b219287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Accuracy of the tuned model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Question 9: Write a Python program to: ‚óè Load the Iris Dataset ‚óè Tune the Decision Tree‚Äôs max_depth and min_samples_split using GridSearchCV ‚óè Print the best parameters and the resulting model accuracy \n",
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2. Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Define Decision Tree and parameter grid\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, None],\n",
    "    'min_samples_split': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# 4. Apply GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 6. Evaluate best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the tuned model:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930feb90-ca43-4b50-86e7-700fbc57f375",
   "metadata": {},
   "source": [
    "# Queation 10:Imagine you‚Äôre working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values. \n",
    "#Explain the step-by-step process you would follow to: ‚óè Handle the missing values ‚óè Encode the categorical features ‚óè Train a Decision Tree model ‚óè Tune its hyperparameters ‚óè Evaluate its performance \n",
    "#And describe what business value this model could provide in the real-world setting. \n",
    "- Step 1: Handle Missing Values\n",
    "\n",
    "Identify missing values in the dataset using .isnull() or .info().\n",
    "\n",
    "Impute missing values:\n",
    "\n",
    "For numerical features, use mean or median.\n",
    "\n",
    "For categorical features, use mode (most frequent value) or a special category like ‚ÄúUnknown‚Äù.\n",
    "\n",
    "Optional: Drop rows or columns if too many values are missing.\n",
    "\n",
    "- Step 2: Encode Categorical Features\n",
    "\n",
    "Convert categorical variables into numbers because Decision Trees in most libraries require numeric input.\n",
    "\n",
    "Use Label Encoding if the feature is ordinal (has order).\n",
    "\n",
    "Use One-Hot Encoding if the feature is nominal (no order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3125de4c-3066-4396-b43f-498f73a25ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example:\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb56d01b-0347-49ce-862f-3fbcaa10b908",
   "metadata": {},
   "source": [
    "Step 3: Train a Decision Tree Model\n",
    "\n",
    "Split the dataset into train and test sets using train_test_split.\n",
    "\n",
    "Train a Decision Tree Classifier on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca986537-11b2-4094-864b-54c88a2925f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d30bf-cded-4070-bb08-6e42e0f67b69",
   "metadata": {},
   "source": [
    "- Step 4: Tune Hyperparameters\n",
    "\n",
    "Use GridSearchCV or RandomizedSearchCV to find the best settings:\n",
    "\n",
    "max_depth ‚Üí controls tree depth\n",
    "\n",
    "min_samples_split ‚Üí min samples to split a node\n",
    "\n",
    "min_samples_leaf ‚Üí min samples at a leaf\n",
    "\n",
    "criterion ‚Üí ‚Äúgini‚Äù or ‚Äúentropy‚Äù\n",
    "\n",
    "This prevents overfitting and improves model performance.\n",
    "\n",
    "- Step 5: Evaluate Performance\n",
    "\n",
    "Use the test set to check accuracy.\n",
    "\n",
    "Use additional metrics like:\n",
    "\n",
    "Precision ‚Üí correct positive predictions / all predicted positive\n",
    "\n",
    "Recall ‚Üí correct positive predictions / all actual positive\n",
    "\n",
    "F1-score ‚Üí balance of precision and recall\n",
    "\n",
    "Confusion matrix ‚Üí shows true/false positives/negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8862b1e-f1cf-4625-a6a8-fe617acc8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#example:\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bda596-0b63-480b-a1b1-5c7753461ca7",
   "metadata": {},
   "source": [
    "- Step 6: Business Value\n",
    "\n",
    "Early disease detection ‚Üí helps doctors take timely actions.\n",
    "\n",
    "Resource optimization ‚Üí prioritize patients at higher risk.\n",
    "\n",
    "Reduce healthcare costs ‚Üí prevent serious complications by early intervention.\n",
    "\n",
    "Personalized care ‚Üí target treatment based on predicted risk.\n",
    "\n",
    "This model can save lives, improve patient care, and reduce costs by identifying high-risk patients before the disease progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52e2d0-03af-4fc5-93c8-0e0d82ac7dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
